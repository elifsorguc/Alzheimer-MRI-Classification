{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Environment check\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers,models\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, MaxPooling2D, Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras import optimizers, losses\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# System libraries\n",
    "from pathlib import Path\n",
    "import os.path\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"../input/augmented-alzheimer-mri-dataset/AugmentedAlzheimerDataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = Path(data)\n",
    "\n",
    "# Get filepaths and labels\n",
    "filepaths = list(image_dir.glob(r'**/*.JPG')) + list(image_dir.glob(r'**/*.jpg')) \n",
    "\n",
    "labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], filepaths))\n",
    "\n",
    "filepaths = pd.Series(filepaths, name='Filepath').astype(str)\n",
    "labels = pd.Series(labels, name='Label')\n",
    "\n",
    "# Concatenate filepaths and labels\n",
    "image_df = pd.concat([filepaths, labels], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "from pathlib import Path\n",
    "from PIL import UnidentifiedImageError\n",
    "\n",
    "path = Path(\"../input/augmented-alzheimer-mri-dataset/AugmentedAlzheimerDataset\").rglob(\"*.jpg\")\n",
    "for img_p in path:\n",
    "    try:\n",
    "        img = PIL.Image.open(img_p)\n",
    "    except PIL.UnidentifiedImageError:\n",
    "            print(img_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display 16 picture of the dataset with their labels\n",
    "random_index = np.random.randint(0, len(image_df), 16)\n",
    "fig, axes = plt.subplots(nrows=4, ncols=4, figsize=(10, 10),\n",
    "                        subplot_kw={'xticks': [], 'yticks': []})\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(plt.imread(image_df.Filepath[random_index[i]]))\n",
    "    ax.set_title(image_df.Label[random_index[i]])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "    validation_split=0.2) # set validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_datagen.flow_from_directory(\n",
    "    data,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='training') # set as training data\n",
    "\n",
    "validation_images = train_datagen.flow_from_directory(\n",
    "    data , # same directory as training data\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='validation') # set as validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    Conv2D(16, (3,3), activation = 'relu', input_shape = (224,224, 3)),\n",
    "    MaxPooling2D(2,2),\n",
    "    Conv2D(32, (3,3), activation = 'relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "    Conv2D(32, (3,3), activation = 'relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "    Conv2D(32, (3,3), activation = 'relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "    Flatten(),\n",
    "    Dense(512, activation = 'relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(4, activation = 'softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy', optimizer = tf.keras.optimizers.Adam(), metrics = ['accuracy'])\n",
    "history = model.fit(train_images,\n",
    "    steps_per_epoch=len(train_images),\n",
    "    validation_data=validation_images,\n",
    "    validation_steps=len(validation_images),\n",
    "    epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get predictions on validation data\n",
    "y_pred = model.predict(validation_images)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)  # Convert probabilities to class indices\n",
    "\n",
    "# Get true labels\n",
    "true_labels = validation_images.classes\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(true_labels, y_pred_classes)\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(true_labels, y_pred_classes)\n",
    "\n",
    "# Display the confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=list(validation_images.class_indices.keys()))\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title(f\"Confusion Matrix (Accuracy: {accuracy:.4f})\")\n",
    "plt.show()\n",
    "\n",
    "# Print accuracy separately as well\n",
    "print(f\"Validation Accuracy: {accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
